{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "295ICGqQXXA7",
    "outputId": "aaf51965-8877-4a8c-c0b3-4f9838252670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'single_label.csv') #Change name here\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfS8m7qAXYAk",
    "outputId": "c1ede4d3-d886-4c64-dc92-c997a9d2771d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "T1027        683\n",
      "T1140        455\n",
      "T1059.003    345\n",
      "T1055        283\n",
      "T1105        262\n",
      "T1106        201\n",
      "T1078        170\n",
      "T1071.001    146\n",
      "T1090        139\n",
      "T1082        137\n",
      "T1003.001    107\n",
      "T1053.005    106\n",
      "T1112        104\n",
      "T1083         98\n",
      "T1562.001     95\n",
      "T1021.001     94\n",
      "T1204.002     87\n",
      "T1070.004     86\n",
      "T1566.001     86\n",
      "T1041         82\n",
      "T1057         82\n",
      "T1574.002     81\n",
      "T1047         75\n",
      "T1036.005     68\n",
      "T1056.001     65\n",
      "T1110         64\n",
      "T1005         64\n",
      "T1547.001     63\n",
      "T1570         57\n",
      "T1016         55\n",
      "T1218.011     53\n",
      "T1219         52\n",
      "T1573.001     52\n",
      "T1190         51\n",
      "T1095         50\n",
      "T1543.003     50\n",
      "T1033         49\n",
      "T1113         48\n",
      "T1518.001     36\n",
      "T1548.002     27\n",
      "T1012         26\n",
      "T1074.001     25\n",
      "T1569.002     23\n",
      "T1484.001     23\n",
      "T1552.001     20\n",
      "T1564.001     17\n",
      "T1210         16\n",
      "T1068         10\n",
      "T1072         10\n",
      "T1557.001      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWu169pYXYDY",
    "outputId": "001a8f66-0a87-4a82-c5d4-9615507e5ada"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS ================== : 51\n",
      "FULL Dataset: (5086, 3)\n",
      "TRAIN Dataset: (4068, 3)\n",
      "TEST Dataset: (1018, 3)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 3.50133\n",
      "Cost at epoch 1 is 2.60356\n",
      "Cost at epoch 2 is 1.87790\n",
      "Cost at epoch 3 is 1.36521\n",
      "Cost at epoch 4 is 1.01949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertConfig, AutoModel,RobertaTokenizer,RobertaModel,RobertaConfig\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "pretrained_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "\"\"\"Set the Runtime to GPU and check and set cuda availability with the following snippet\"\"\"\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device\n",
    "\n",
    "LABELS = len(df['label'].unique())\n",
    "print(\"LABELS ================== :\", LABELS)\n",
    "\n",
    "\"\"\"Substitute dataset file name with your own\"\"\"\n",
    "def experiment(seed):\n",
    "\tstart_time = time.time()  # Record the start time\n",
    "\tdf = pd.read_csv(r'single_label.csv') #Change name here\n",
    "\n",
    "\tLABELS = len(df['label'].unique())\n",
    "\n",
    "\t#Encoding labels\n",
    "\tencoder = LabelEncoder()\n",
    "\tencoder.fit(df['label'])\n",
    "\tdf['enc_Domain'] = encoder.transform(df['label'])\n",
    "\n",
    "\tdf = df[['label', 'text', 'enc_Domain']]\n",
    "\tLABELS\n",
    "\n",
    "\t\"\"\"# Model\"\"\"\n",
    "\n",
    "\t# Defining some key variables that will be used later on in the training\n",
    "\tMAX_LEN = 512\n",
    "\tTRAIN_BATCH_SIZE = 16\n",
    "\tVALID_BATCH_SIZE = 16\n",
    "\tEPOCHS = 20\n",
    "\tLEARNING_RATE = 1e-05\n",
    "\n",
    "\tclass Triage(Dataset):\n",
    "\t\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\t\tself.len = len(dataframe)\n",
    "\t\t\tself.data = dataframe\n",
    "\t\t\tself.tokenizer = tokenizer\n",
    "\t\t\tself.max_len = max_len\n",
    "\n",
    "\t\tdef __getitem__(self, index):\n",
    "\t\t\tsentence = str(self.data.text[index])\n",
    "\t\t\tsentence = \" \".join(sentence.split())\n",
    "\t\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\t\tsentence,\n",
    "\t\t\t\tNone,\n",
    "\t\t\t\tadd_special_tokens=True,\n",
    "\t\t\t\tmax_length=self.max_len,\n",
    "\t\t\t\tpadding='max_length',\n",
    "\t\t\t\treturn_token_type_ids=True,\n",
    "\t\t\t\ttruncation=True\n",
    "\t\t\t)\n",
    "\t\t\tids = inputs['input_ids']\n",
    "\t\t\tmask = inputs['attention_mask']\n",
    "\n",
    "\t\t\tif 'enc_Domain' not in self.data:\n",
    "\t\t\t\treturn {\n",
    "\t\t\t\t'ids': torch.tensor(ids, dtype=torch.long),\n",
    "\t\t\t\t'mask': torch.tensor(mask, dtype=torch.long)\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'ids': torch.tensor(ids, dtype=torch.long),\n",
    "\t\t\t\t'mask': torch.tensor(mask, dtype=torch.long),\n",
    "\t\t\t\t'targets': torch.tensor(self.data.enc_Domain[index], dtype=torch.long)\n",
    "\t\t\t}\n",
    "\n",
    "\t\tdef __len__(self):\n",
    "\t\t\treturn self.len\n",
    "\texperiment_seed = seed\n",
    "\t#Split dataset into train and validation\n",
    "\ttrain_indices, test_indices = train_test_split(list(range(len(df.enc_Domain))), random_state = seed, test_size=0.2, stratify=df.enc_Domain)\n",
    "\n",
    "\ttrain_dataset = df.copy().drop(test_indices).reset_index(drop=True)\n",
    "\ttest_dataset = df.copy().drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\tprint(\"FULL Dataset: {}\".format(df.shape))\n",
    "\tprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "\tprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "\ttraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "\ttesting_set = Triage(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "\ttrain_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "\t\t        'shuffle': True,\n",
    "\t\t        'num_workers': 0\n",
    "\t\t        }\n",
    "\n",
    "\ttest_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "\t\t        'shuffle': True,\n",
    "\t\t        'num_workers': 0\n",
    "\t\t        }\n",
    "\n",
    "\ttraining_loader = DataLoader(training_set, **train_params)\n",
    "\ttesting_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\t# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "\n",
    "\tclass BERTClass(torch.nn.Module):\n",
    "\t\tdef __init__(self, pretrained_model_name: str, num_classes: int = None, dropout: float = 0.5):\n",
    "\t\t\tsuper().__init__()\n",
    "\t\t\tconfig = BertConfig.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
    "\t\t\tself.model = AutoModelForMaskedLM.from_pretrained(pretrained_model_name, config=config).base_model #pick only the main body of the model\n",
    "\t\t\t#for param in self.model.parameters():\n",
    "\t\t\t#param.requires_grad = False\n",
    "\t\t\tself.pre_classifier = torch.nn.Linear(768, 768)\n",
    "\t\t\tself.dropout = torch.nn.Dropout(dropout)\n",
    "\t\t\tself.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "\t\tdef forward(self, input_ids, attention_mask):\n",
    "\t\t\toutput_1 = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\t\t\thidden_state = output_1[0]\n",
    "\t\t\tpooler = hidden_state[:, 0]\n",
    "\t\t\tpooler = self.pre_classifier(pooler)\n",
    "\t\t\tpooler = torch.nn.ReLU()(pooler)\n",
    "\t\t\tpooler = self.dropout(pooler)\n",
    "\t\t\toutput = self.classifier(pooler)\n",
    "\t\t\treturn output\n",
    "\n",
    "\t#LOAD\n",
    "\tmodel = BERTClass(\"bert-base-uncased\", LABELS)\n",
    "\n",
    "\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tmodel.to(device)\n",
    "\n",
    "\t# Creating the loss function and optimizer\n",
    "\tloss_function = torch.nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\t# Function to calcuate the accuracy of the model\n",
    "\tdef calcuate_accu(big_idx, targets):\n",
    "\t\tn_correct = (big_idx==targets).sum().item()\n",
    "\t\treturn n_correct\n",
    "\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\t# Defining the training function on the 80% of the dataset for tuning the secbert model\n",
    "\tdef train(epoch):\n",
    "\t\ttr_loss = 0\n",
    "\t\tn_correct = 0\n",
    "\t\tnb_tr_steps = 0\n",
    "\t\texamples = len(train_dataset)\n",
    "\t\tlosses = [None] * len(training_loader)\n",
    "\t\tmodel.train()\n",
    "\t\t#loop = tqdm(enumerate(training_loader), total=len(training_loader), leave=False)\n",
    "\t\tfor i, data in enumerate(training_loader, 0):\n",
    "\t\t\t#print(i)\n",
    "\t\t\tids = data['ids'].to(device, dtype = torch.long)\n",
    "\t\t\tmask = data['mask'].to(device, dtype = torch.long)\n",
    "\t\t\ttargets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "\t\t\toutputs = model(ids, mask)\n",
    "\t\t\tloss = loss_function(outputs, targets)\n",
    "\n",
    "\t\t\tlosses[i] = loss.item()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t# # When using GPU\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\tprint(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tfor epoch in range(EPOCHS):\n",
    "\t\ttrain(epoch)\n",
    "\n",
    "\tdef check_accuracy(loader, model):\n",
    "\n",
    "\t\t#pred = []\n",
    "\t\tnum_correct = 0\n",
    "\t\tnum_samples = 0\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i, data in enumerate(loader, 0):\n",
    "\t\t\t\tx = data['ids'].to(device, dtype = torch.long)\n",
    "\t\t\t\tmask = data['mask'].to(device, dtype = torch.long)\n",
    "\t\t\t\ty = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "\t\t\t\tscores = model(x, mask)\n",
    "\t\t\t\t_, predictions = scores.max(1)\n",
    "\t\t\t\tnum_correct += (predictions == y).sum()\n",
    "\t\t\t\tnum_samples += predictions.size(0)\n",
    "\t\t\t\tpred.append(predictions.cpu().numpy())\n",
    "\t\t\t\ty_test.append(y.cpu().numpy())\n",
    "\n",
    "\n",
    "\t\t\tprint(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "\n",
    "\tpred=[]\n",
    "\ty_pred =[]\n",
    "\ty_test =[]\n",
    "\ty =[]\n",
    "\n",
    "\t\"\"\"Save the model for further tests\"\"\"\n",
    "\n",
    "\tcheck_accuracy(testing_loader, model)\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tt = pred[i]\n",
    "\t\tfor j in range(len(t)):\n",
    "\t\t\ty_pred.append(t[j])\n",
    "\n",
    "\tfor i in range(len(y_test)):\n",
    "\t\tt = y_test[i]\n",
    "\t\tfor j in range(len(t)):\n",
    "\t\t\ty.append(t[j])\n",
    "\n",
    "\tfrom sklearn.metrics import classification_report,accuracy_score\n",
    "\tprint(classification_report(y, y_pred))\n",
    "\n",
    "\tlabels = list(encoder.inverse_transform([0,1,2,3,4,5]))\n",
    "\n",
    "\tfrom sklearn.metrics import classification_report\n",
    "\n",
    "\t# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "\t# Calculate classification report\n",
    "\treport = classification_report(y, y_pred, target_names = labels, digits=4, output_dict=True)\n",
    "\n",
    "\t# Access the weighted F1 score, recall, and precision\n",
    "\tf1_weighted = report['weighted avg']['f1-score']\n",
    "\trecall_weighted = report['weighted avg']['recall']\n",
    "\tprecision_weighted = report['weighted avg']['precision']\n",
    "\taccuracy=accuracy_score(y,y_pred)\n",
    "\t# Access the macro-averaged F1 score, recall, and precision\n",
    "\tf1_macro = report['macro avg']['f1-score']\n",
    "\trecall_macro = report['macro avg']['recall']\n",
    "\tprecision_macro = report['macro avg']['precision']\n",
    "\n",
    "\t# Print the results\n",
    "\tprint(\"Weighted Precision:\", precision_weighted)\n",
    "\tprint(\"Weighted Recall:\", recall_weighted)\n",
    "\tprint(\"Weighted F1 Score:\", f1_weighted)\n",
    "\n",
    "\t# Print the results\n",
    "\tprint(\"Macro Precision:\", f1_macro)\n",
    "\tprint(\"Macro Recall:\", recall_macro)\n",
    "\tprint(\"Macro F1 Score:\", precision_macro)\n",
    "\tprint(\"Accuracy: \", accuracy)\n",
    "\n",
    "\tfrom sklearn.metrics import confusion_matrix\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport seaborn as sns\n",
    "\tfig, ax = plt.subplots(figsize=(7, 7))\n",
    "\tcm_array = confusion_matrix(y, y_pred)\n",
    "\tcm_labels = np.unique(labels)\n",
    "\tcm_array_df = pd.DataFrame(cm_array, index=cm_labels)\n",
    "\tsns.heatmap(cm_array_df, annot=True,\n",
    "\t\t    cbar=False, fmt='1d', cmap='Blues', ax=ax)\n",
    "\tax.set_title('Confusion Matrix', loc='left', fontsize=16)\n",
    "\tax.set_xlabel('Predicted',fontsize=16)\n",
    "\tax.set_ylabel('Actual',fontsize=16)\n",
    "\timage_name = f\"confusion_matrix_{experiment_seed}.png\"\n",
    "\tplt.savefig(image_name)\n",
    "\t# Calculate and print execution time\n",
    "\tend_time = time.time()\n",
    "\texecution_time = end_time - start_time\n",
    "\tprint(f\"Execution Time: {execution_time} seconds\")\n",
    "\t# Appending classification report, confusion matrix text, and confusion matrix image path to the same text file\n",
    "\twith open(\"BERTBase_result.txt\", \"a\") as file:\n",
    "\t\tfile.write(\"\\n\\nBERTBase Result:\\n\\n\")\n",
    "\t\tfile.write(f\"\\n\\nSeed Value: {experiment_seed}\")\n",
    "\t\tfile.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "\t\tfile.write(classification_report(y, y_pred, target_names = labels))\n",
    "\t\tfile.write(f\"\\n\\nWeighted Precision: {precision_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\nWeighted Recall: {recall_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\nWeighted F1 Score: {f1_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\Macro Precision: {precision_macro}\")\n",
    "\t\tfile.write(f\"\\n\\Macro Recall: {recall_macro}\")\n",
    "\t\tfile.write(f\"\\n\\Macro F1 Score: {f1_macro}\")\n",
    "\t\tfile.write(f\"\\n\\nAccuracy: {accuracy}\")\n",
    "\t\tfile.write(\"\\n\\nConfusion Matrix Image Path:\\n\\n\")\n",
    "\t\tfile.write(image_name)\n",
    "\t\tfile.write(f\"\\n\\nExecution Time: {execution_time} seconds\")\n",
    "experiment(2092)\n",
    "experiment(22)\n",
    "experiment(1517)\n",
    "experiment(919)\n",
    "experiment(2455)\n",
    "experiment(65)\n",
    "experiment(2167)\n",
    "experiment(246)\n",
    "experiment(1159)\n",
    "experiment(2679)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtTXWBxEXYLJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CrBOIZDQQw2",
    "outputId": "1dca7a11-f79f-4026-b305-373a41b42b3b"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= UNIQUE LABELS =========== :  51\n",
      "FULL Dataset: (5086, 3)\n",
      "TRAIN Dataset: (4068, 3)\n",
      "TEST Dataset: (1018, 3)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertConfig, AutoModel,RobertaTokenizer,RobertaModel,RobertaConfig\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "pretrained_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "\n",
    "\"\"\"Set the Runtime to GPU and check and set cuda availability with the following snippet\"\"\"\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device\n",
    "\n",
    "df = pd.read_csv(r'single_label.csv') #Change name here\n",
    "LABELS = len(df['label'].unique())\n",
    "print(\"========= UNIQUE LABELS =========== : \", LABELS)\n",
    "\n",
    "\"\"\"Substitute dataset file name with your own\"\"\"\n",
    "def experiment(seed):\n",
    "\tstart_time = time.time()  # Record the start time\n",
    "\tdf = pd.read_csv(r'single_label.csv') #Change name here\n",
    "\n",
    "\tLABELS = len(df['label'].unique())\n",
    "\n",
    "\t#Encoding labels\n",
    "\tencoder = LabelEncoder()\n",
    "\tencoder.fit(df['label'])\n",
    "\tdf['enc_Domain'] = encoder.transform(df['label'])\n",
    "\n",
    "\tdf = df[['label', 'text', 'enc_Domain']]\n",
    "\tLABELS\n",
    "\n",
    "\t\"\"\"# Model\"\"\"\n",
    "\n",
    "\t# Defining some key variables that will be used later on in the training\n",
    "\tMAX_LEN = 512\n",
    "\tTRAIN_BATCH_SIZE = 16\n",
    "\tVALID_BATCH_SIZE = 16\n",
    "\tEPOCHS = 20\n",
    "\tLEARNING_RATE = 1e-05\n",
    "\n",
    "\tclass Triage(Dataset):\n",
    "\t\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\t\tself.len = len(dataframe)\n",
    "\t\t\tself.data = dataframe\n",
    "\t\t\tself.tokenizer = tokenizer\n",
    "\t\t\tself.max_len = max_len\n",
    "\n",
    "\t\tdef __getitem__(self, index):\n",
    "\t\t\tsentence = str(self.data.text[index])\n",
    "\t\t\tsentence = \" \".join(sentence.split())\n",
    "\t\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\t\tsentence,\n",
    "\t\t\t\tNone,\n",
    "\t\t\t\tadd_special_tokens=True,\n",
    "\t\t\t\tmax_length=self.max_len,\n",
    "\t\t\t\tpadding='max_length',\n",
    "\t\t\t\treturn_token_type_ids=True,\n",
    "\t\t\t\ttruncation=True\n",
    "\t\t\t)\n",
    "\t\t\tids = inputs['input_ids']\n",
    "\t\t\tmask = inputs['attention_mask']\n",
    "\n",
    "\t\t\tif 'enc_Domain' not in self.data:\n",
    "\t\t\t\treturn {\n",
    "\t\t\t\t'ids': torch.tensor(ids, dtype=torch.long),\n",
    "\t\t\t\t'mask': torch.tensor(mask, dtype=torch.long)\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'ids': torch.tensor(ids, dtype=torch.long),\n",
    "\t\t\t\t'mask': torch.tensor(mask, dtype=torch.long),\n",
    "\t\t\t\t'targets': torch.tensor(self.data.enc_Domain[index], dtype=torch.long)\n",
    "\t\t\t}\n",
    "\n",
    "\t\tdef __len__(self):\n",
    "\t\t\treturn self.len\n",
    "\texperiment_seed = seed\n",
    "\t#Split dataset into train and validation\n",
    "\ttrain_indices, test_indices = train_test_split(list(range(len(df.enc_Domain))), random_state = seed, test_size=0.2, stratify=df.enc_Domain)\n",
    "\n",
    "\ttrain_dataset = df.copy().drop(test_indices).reset_index(drop=True)\n",
    "\ttest_dataset = df.copy().drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\tprint(\"FULL Dataset: {}\".format(df.shape))\n",
    "\tprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "\tprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "\ttraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "\ttesting_set = Triage(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "\ttrain_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "\t\t        'shuffle': True,\n",
    "\t\t        'num_workers': 0\n",
    "\t\t        }\n",
    "\n",
    "\ttest_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "\t\t        'shuffle': True,\n",
    "\t\t        'num_workers': 0\n",
    "\t\t        }\n",
    "\n",
    "\ttraining_loader = DataLoader(training_set, **train_params)\n",
    "\ttesting_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\t# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "\n",
    "\tclass BERTClass(torch.nn.Module):\n",
    "\t\tdef __init__(self, pretrained_model_name: str, num_classes: int = None, dropout: float = 0.5):\n",
    "\t\t\tsuper().__init__()\n",
    "\t\t\tconfig = BertConfig.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
    "\t\t\tself.model = AutoModelForMaskedLM.from_pretrained(pretrained_model_name, config=config).base_model #pick only the main body of the model\n",
    "\t\t\t#for param in self.model.parameters():\n",
    "\t\t\t#param.requires_grad = False\n",
    "\t\t\tself.pre_classifier = torch.nn.Linear(768, 768)\n",
    "\t\t\tself.dropout = torch.nn.Dropout(dropout)\n",
    "\t\t\tself.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "\t\tdef forward(self, input_ids, attention_mask):\n",
    "\t\t\toutput_1 = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\t\t\thidden_state = output_1[0]\n",
    "\t\t\tpooler = hidden_state[:, 0]\n",
    "\t\t\tpooler = self.pre_classifier(pooler)\n",
    "\t\t\tpooler = torch.nn.ReLU()(pooler)\n",
    "\t\t\tpooler = self.dropout(pooler)\n",
    "\t\t\toutput = self.classifier(pooler)\n",
    "\t\t\treturn output\n",
    "\n",
    "\t#LOAD\n",
    "\tmodel = BERTClass(\"bert-base-uncased\", LABELS)\n",
    "\n",
    "\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tmodel.to(device)\n",
    "\n",
    "\t# Creating the loss function and optimizer\n",
    "\tloss_function = torch.nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\t# Function to calcuate the accuracy of the model\n",
    "\tdef calcuate_accu(big_idx, targets):\n",
    "\t\tn_correct = (big_idx==targets).sum().item()\n",
    "\t\treturn n_correct\n",
    "\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "\t# Defining the training function on the 80% of the dataset for tuning the secbert model\n",
    "\tdef train(epoch):\n",
    "\t\ttr_loss = 0\n",
    "\t\tn_correct = 0\n",
    "\t\tnb_tr_steps = 0\n",
    "\t\texamples = len(train_dataset)\n",
    "\t\tlosses = [None] * len(training_loader)\n",
    "\t\tmodel.train()\n",
    "\t\t#loop = tqdm(enumerate(training_loader), total=len(training_loader), leave=False)\n",
    "\t\tfor i, data in enumerate(training_loader, 0):\n",
    "\t\t\t#print(i)\n",
    "\t\t\tids = data['ids'].to(device, dtype = torch.long)\n",
    "\t\t\tmask = data['mask'].to(device, dtype = torch.long)\n",
    "\t\t\ttargets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "\t\t\toutputs = model(ids, mask)\n",
    "\t\t\tloss = loss_function(outputs, targets)\n",
    "\n",
    "\t\t\tlosses[i] = loss.item()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t# # When using GPU\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\tprint(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tfor epoch in range(EPOCHS):\n",
    "\t\ttrain(epoch)\n",
    "\n",
    "\tdef check_accuracy(loader, model):\n",
    "\n",
    "\t\t#pred = []\n",
    "\t\tnum_correct = 0\n",
    "\t\tnum_samples = 0\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i, data in enumerate(loader, 0):\n",
    "\t\t\t\tx = data['ids'].to(device, dtype = torch.long)\n",
    "\t\t\t\tmask = data['mask'].to(device, dtype = torch.long)\n",
    "\t\t\t\ty = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "\t\t\t\tscores = model(x, mask)\n",
    "\t\t\t\t_, predictions = scores.max(1)\n",
    "\t\t\t\tnum_correct += (predictions == y).sum()\n",
    "\t\t\t\tnum_samples += predictions.size(0)\n",
    "\t\t\t\tpred.append(predictions.cpu().numpy())\n",
    "\t\t\t\ty_test.append(y.cpu().numpy())\n",
    "\n",
    "\n",
    "\t\t\tprint(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "\n",
    "\tpred=[]\n",
    "\ty_pred =[]\n",
    "\ty_test =[]\n",
    "\ty =[]\n",
    "\n",
    "\t\"\"\"Save the model for further tests\"\"\"\n",
    "\n",
    "\tcheck_accuracy(testing_loader, model)\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tt = pred[i]\n",
    "\t\tfor j in range(len(t)):\n",
    "\t\t\ty_pred.append(t[j])\n",
    "\n",
    "\tfor i in range(len(y_test)):\n",
    "\t\tt = y_test[i]\n",
    "\t\tfor j in range(len(t)):\n",
    "\t\t\ty.append(t[j])\n",
    "\n",
    "\tfrom sklearn.metrics import classification_report,accuracy_score\n",
    "\tprint(classification_report(y, y_pred))\n",
    "\n",
    "\tlabels = list(encoder.inverse_transform([0,1,2,3,4,5]))\n",
    "\n",
    "\tfrom sklearn.metrics import classification_report\n",
    "\n",
    "\t# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "\t# Calculate classification report\n",
    "\treport = classification_report(y, y_pred, target_names = labels, digits=4, output_dict=True)\n",
    "\n",
    "\t# Access the weighted F1 score, recall, and precision\n",
    "\tf1_weighted = report['weighted avg']['f1-score']\n",
    "\trecall_weighted = report['weighted avg']['recall']\n",
    "\tprecision_weighted = report['weighted avg']['precision']\n",
    "\taccuracy=accuracy_score(y,y_pred)\n",
    "\t# Access the macro-averaged F1 score, recall, and precision\n",
    "\tf1_macro = report['macro avg']['f1-score']\n",
    "\trecall_macro = report['macro avg']['recall']\n",
    "\tprecision_macro = report['macro avg']['precision']\n",
    "\n",
    "\t# Print the results\n",
    "\tprint(\"Weighted Precision:\", precision_weighted)\n",
    "\tprint(\"Weighted Recall:\", recall_weighted)\n",
    "\tprint(\"Weighted F1 Score:\", f1_weighted)\n",
    "\n",
    "\t# Print the results\n",
    "\tprint(\"Macro Precision:\", f1_macro)\n",
    "\tprint(\"Macro Recall:\", recall_macro)\n",
    "\tprint(\"Macro F1 Score:\", precision_macro)\n",
    "\tprint(\"Accuracy: \", accuracy)\n",
    "\n",
    "\tfrom sklearn.metrics import confusion_matrix\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport seaborn as sns\n",
    "\tfig, ax = plt.subplots(figsize=(7, 7))\n",
    "\tcm_array = confusion_matrix(y, y_pred)\n",
    "\tcm_labels = np.unique(labels)\n",
    "\tcm_array_df = pd.DataFrame(cm_array, index=cm_labels)\n",
    "\tsns.heatmap(cm_array_df, annot=True,\n",
    "\t\t    cbar=False, fmt='1d', cmap='Blues', ax=ax)\n",
    "\tax.set_title('Confusion Matrix', loc='left', fontsize=16)\n",
    "\tax.set_xlabel('Predicted',fontsize=16)\n",
    "\tax.set_ylabel('Actual',fontsize=16)\n",
    "\timage_name = f\"confusion_matrix_{experiment_seed}.png\"\n",
    "\tplt.savefig(image_name)\n",
    "\t# Calculate and print execution time\n",
    "\tend_time = time.time()\n",
    "\texecution_time = end_time - start_time\n",
    "\tprint(f\"Execution Time: {execution_time} seconds\")\n",
    "\t# Appending classification report, confusion matrix text, and confusion matrix image path to the same text file\n",
    "\twith open(\"BERTBase_result.txt\", \"a\") as file:\n",
    "\t\tfile.write(\"\\n\\nBERTBase Result:\\n\\n\")\n",
    "\t\tfile.write(f\"\\n\\nSeed Value: {experiment_seed}\")\n",
    "\t\tfile.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "\t\tfile.write(classification_report(y, y_pred, target_names = labels))\n",
    "\t\tfile.write(f\"\\n\\nWeighted Precision: {precision_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\nWeighted Recall: {recall_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\nWeighted F1 Score: {f1_weighted}\")\n",
    "\t\tfile.write(f\"\\n\\Macro Precision: {precision_macro}\")\n",
    "\t\tfile.write(f\"\\n\\Macro Recall: {recall_macro}\")\n",
    "\t\tfile.write(f\"\\n\\Macro F1 Score: {f1_macro}\")\n",
    "\t\tfile.write(f\"\\n\\nAccuracy: {accuracy}\")\n",
    "\t\tfile.write(\"\\n\\nConfusion Matrix Image Path:\\n\\n\")\n",
    "\t\tfile.write(image_name)\n",
    "\t\tfile.write(f\"\\n\\nExecution Time: {execution_time} seconds\")\n",
    "experiment(2092)\n",
    "experiment(22)\n",
    "experiment(1517)\n",
    "experiment(919)\n",
    "experiment(2455)\n",
    "experiment(65)\n",
    "experiment(2167)\n",
    "experiment(246)\n",
    "experiment(1159)\n",
    "experiment(2679)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
